01/04/2024 13:56:31 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/04/2024 13:56:32 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file=None, output_folder_name='CODEBERTRQm_bugtype_mixed', output_dir='./saved_models', eval_data_file=None, test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/test.jsonl', model_type='roberta', model_name_or_path='/data2/chenlida/model/codebert-base', mlm=False, mlm_probability=0.15, config_name='', tokenizer_name='/data2/chenlida/model/codebert-base', cache_dir='', block_size=400, do_train=False, do_eval=False, do_test=True, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=1, epoch=5, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', lamda_1=0.5, old_lora='', n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
01/04/2024 13:56:40 - INFO - __main__ -   ***** Running Test *****
01/04/2024 13:56:40 - INFO - __main__ -     Num examples = 2551
01/04/2024 13:56:40 - INFO - __main__ -     Batch size = 64
>>>>>>>>>>>>>>
checkpoint-best-accCODEBERTRQm_bugtype_mixed>>>>>>>>>>>>>

  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:02<01:20,  2.06s/it]  5%|▌         | 2/40 [00:02<00:39,  1.05s/it]  8%|▊         | 3/40 [00:02<00:26,  1.38it/s] 10%|█         | 4/40 [00:03<00:20,  1.75it/s] 12%|█▎        | 5/40 [00:03<00:17,  2.05it/s] 15%|█▌        | 6/40 [00:03<00:14,  2.29it/s] 18%|█▊        | 7/40 [00:04<00:13,  2.47it/s] 20%|██        | 8/40 [00:04<00:12,  2.60it/s] 22%|██▎       | 9/40 [00:04<00:11,  2.69it/s] 25%|██▌       | 10/40 [00:05<00:10,  2.76it/s] 28%|██▊       | 11/40 [00:05<00:10,  2.81it/s] 30%|███       | 12/40 [00:05<00:09,  2.85it/s] 32%|███▎      | 13/40 [00:06<00:09,  2.86it/s] 35%|███▌      | 14/40 [00:06<00:09,  2.88it/s] 38%|███▊      | 15/40 [00:06<00:09,  2.75it/s] 40%|████      | 16/40 [00:07<00:08,  2.75it/s] 42%|████▎     | 17/40 [00:07<00:08,  2.69it/s] 45%|████▌     | 18/40 [00:07<00:07,  2.76it/s] 48%|████▊     | 19/40 [00:08<00:07,  2.77it/s] 50%|█████     | 20/40 [00:08<00:07,  2.81it/s] 52%|█████▎    | 21/40 [00:09<00:07,  2.47it/s] 55%|█████▌    | 22/40 [00:09<00:08,  2.19it/s] 57%|█████▊    | 23/40 [00:10<00:07,  2.38it/s] 60%|██████    | 24/40 [00:10<00:06,  2.52it/s] 62%|██████▎   | 25/40 [00:10<00:05,  2.64it/s] 65%|██████▌   | 26/40 [00:11<00:05,  2.72it/s] 68%|██████▊   | 27/40 [00:11<00:04,  2.71it/s] 70%|███████   | 28/40 [00:11<00:04,  2.78it/s] 72%|███████▎  | 29/40 [00:12<00:03,  2.83it/s] 75%|███████▌  | 30/40 [00:12<00:03,  2.86it/s] 78%|███████▊  | 31/40 [00:12<00:03,  2.88it/s] 80%|████████  | 32/40 [00:13<00:02,  2.84it/s] 82%|████████▎ | 33/40 [00:13<00:02,  2.87it/s] 85%|████████▌ | 34/40 [00:14<00:02,  2.66it/s] 88%|████████▊ | 35/40 [00:14<00:01,  2.74it/s] 90%|█████████ | 36/40 [00:14<00:01,  2.80it/s] 92%|█████████▎| 37/40 [00:15<00:01,  2.84it/s] 95%|█████████▌| 38/40 [00:15<00:00,  2.86it/s] 98%|█████████▊| 39/40 [00:15<00:00,  2.87it/s]100%|██████████| 40/40 [00:16<00:00,  2.84it/s]100%|██████████| 40/40 [00:16<00:00,  2.49it/s]

Accuracy: 0.8604468835750686
Precision: 0.20954907161803712
F-measure: 0.3073929961089494
Recall: 0.5766423357664233

01/04/2024 13:58:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/04/2024 13:58:31 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file=None, output_folder_name='CODEBERTRQm_bugtype_mixed', output_dir='./saved_models', eval_data_file=None, test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_value_propagation_errors/test.jsonl', model_type='roberta', model_name_or_path='/data2/chenlida/model/codebert-base', mlm=False, mlm_probability=0.15, config_name='', tokenizer_name='/data2/chenlida/model/codebert-base', cache_dir='', block_size=400, do_train=False, do_eval=False, do_test=True, evaluate_during_training=True, do_lower_case=False, train_batch_size=32, eval_batch_size=64, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=50, save_steps=50, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=1, epoch=5, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', lamda_1=0.5, old_lora='', n_gpu=1, device=device(type='cuda'), per_gpu_train_batch_size=32, per_gpu_eval_batch_size=64, start_epoch=0, start_step=0)
01/04/2024 13:58:36 - INFO - __main__ -   ***** Running Test *****
01/04/2024 13:58:36 - INFO - __main__ -     Num examples = 1512
01/04/2024 13:58:36 - INFO - __main__ -     Batch size = 64
>>>>>>>>>>>>>>
checkpoint-best-accCODEBERTRQm_bugtype_mixed>>>>>>>>>>>>>

  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:35,  1.53s/it]  8%|▊         | 2/24 [00:01<00:18,  1.20it/s] 12%|█▎        | 3/24 [00:02<00:14,  1.43it/s] 17%|█▋        | 4/24 [00:02<00:11,  1.80it/s] 21%|██        | 5/24 [00:03<00:09,  2.08it/s] 25%|██▌       | 6/24 [00:03<00:07,  2.31it/s] 29%|██▉       | 7/24 [00:03<00:06,  2.48it/s] 33%|███▎      | 8/24 [00:04<00:06,  2.60it/s] 38%|███▊      | 9/24 [00:04<00:06,  2.41it/s] 42%|████▏     | 10/24 [00:04<00:05,  2.54it/s] 46%|████▌     | 11/24 [00:05<00:04,  2.65it/s] 50%|█████     | 12/24 [00:05<00:04,  2.73it/s] 54%|█████▍    | 13/24 [00:05<00:03,  2.78it/s] 58%|█████▊    | 14/24 [00:06<00:03,  2.82it/s] 62%|██████▎   | 15/24 [00:06<00:03,  2.85it/s] 67%|██████▋   | 16/24 [00:07<00:02,  2.87it/s] 71%|███████   | 17/24 [00:07<00:02,  2.88it/s] 75%|███████▌  | 18/24 [00:07<00:02,  2.89it/s] 79%|███████▉  | 19/24 [00:08<00:01,  2.90it/s] 83%|████████▎ | 20/24 [00:08<00:01,  2.91it/s] 88%|████████▊ | 21/24 [00:08<00:01,  2.91it/s] 92%|█████████▏| 22/24 [00:09<00:00,  2.92it/s] 96%|█████████▌| 23/24 [00:09<00:00,  2.91it/s]100%|██████████| 24/24 [00:09<00:00,  3.28it/s]100%|██████████| 24/24 [00:09<00:00,  2.49it/s]

Accuracy: 0.8458994708994709
Precision: 0.2145748987854251
F-measure: 0.3126843657817109
Recall: 0.5760869565217391

12/25/2023 22:52:20 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:52:24 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_value_propagation_errors/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_privilege_escalation_authorization', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_value_propagation_errors/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_value_propagation_errors/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_privilege_escalation_authorization/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/1512 [00:00<?, ?it/s]load dataset:   4%|▍         | 64/1512 [00:00<00:02, 631.29it/s]load dataset:   9%|▊         | 132/1512 [00:00<00:02, 653.85it/s]load dataset:  13%|█▎        | 198/1512 [00:00<00:02, 523.89it/s]load dataset:  18%|█▊        | 270/1512 [00:00<00:02, 582.17it/s]load dataset:  23%|██▎       | 352/1512 [00:00<00:01, 657.54it/s]load dataset:  28%|██▊       | 429/1512 [00:00<00:01, 692.19it/s]load dataset:  34%|███▎      | 508/1512 [00:00<00:01, 721.28it/s]load dataset:  38%|███▊      | 582/1512 [00:00<00:01, 724.56it/s]load dataset:  43%|████▎     | 656/1512 [00:00<00:01, 695.94it/s]load dataset:  48%|████▊     | 727/1512 [00:01<00:01, 616.89it/s]load dataset:  52%|█████▏    | 791/1512 [00:01<00:01, 515.69it/s]load dataset:  56%|█████▋    | 852/1512 [00:01<00:01, 535.32it/s]load dataset:  60%|██████    | 909/1512 [00:01<00:01, 541.95it/s]load dataset:  65%|██████▍   | 981/1512 [00:01<00:00, 589.14it/s]load dataset:  69%|██████▉   | 1043/1512 [00:01<00:00, 543.27it/s]load dataset:  73%|███████▎  | 1100/1512 [00:01<00:00, 465.07it/s]load dataset:  77%|███████▋  | 1171/1512 [00:02<00:00, 521.26it/s]load dataset:  82%|████████▏ | 1234/1512 [00:02<00:00, 548.87it/s]load dataset:  86%|████████▌ | 1298/1512 [00:02<00:00, 558.64it/s]load dataset:  90%|████████▉ | 1356/1512 [00:02<00:00, 555.88it/s]load dataset:  94%|█████████▍| 1425/1512 [00:02<00:00, 591.86it/s]load dataset:  98%|█████████▊| 1486/1512 [00:02<00:00, 456.95it/s]load dataset: 100%|██████████| 1512/1512 [00:02<00:00, 555.94it/s]
12/25/2023 22:52:30 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:52:30 - INFO - __main__ -     Num examples = 1512
12/25/2023 22:52:30 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/3 [00:00<?, ?it/s]evaluate test:  33%|███▎      | 1/3 [00:04<00:09,  4.51s/it]evaluate test:  67%|██████▋   | 2/3 [00:07<00:03,  3.88s/it]evaluate test: 100%|██████████| 3/3 [00:11<00:00,  3.60s/it]evaluate test: 100%|██████████| 3/3 [00:11<00:00,  3.74s/it]
12/25/2023 22:52:41 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:52:41 - INFO - __main__ -     test_accuracy = 0.9841
12/25/2023 22:52:41 - INFO - __main__ -     test_f1 = 0.8605
12/25/2023 22:52:41 - INFO - __main__ -     test_precision = 0.925
12/25/2023 22:52:41 - INFO - __main__ -     test_recall = 0.8043
12/25/2023 22:52:41 - INFO - __main__ -     test_threshold = 0.5

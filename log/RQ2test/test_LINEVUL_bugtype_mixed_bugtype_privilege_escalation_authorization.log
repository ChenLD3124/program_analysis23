12/25/2023 22:45:05 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:45:08 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_mixed', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_mixed/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3274 [00:00<?, ?it/s]load dataset:   2%|▏         | 50/3274 [00:00<00:06, 485.12it/s]load dataset:   3%|▎         | 100/3274 [00:00<00:06, 488.33it/s]load dataset:   5%|▍         | 150/3274 [00:00<00:06, 491.79it/s]load dataset:   6%|▌         | 200/3274 [00:00<00:07, 432.54it/s]load dataset:   8%|▊         | 261/3274 [00:00<00:06, 490.08it/s]load dataset:  10%|▉         | 312/3274 [00:00<00:06, 489.80it/s]load dataset:  12%|█▏        | 401/3274 [00:00<00:04, 613.34it/s]load dataset:  14%|█▍        | 464/3274 [00:00<00:04, 562.79it/s]load dataset:  17%|█▋        | 565/3274 [00:00<00:03, 689.08it/s]load dataset:  20%|██        | 660/3274 [00:01<00:03, 764.40it/s]load dataset:  23%|██▎       | 739/3274 [00:01<00:03, 726.29it/s]load dataset:  25%|██▍       | 814/3274 [00:01<00:04, 577.63it/s]load dataset:  27%|██▋       | 878/3274 [00:01<00:05, 438.86it/s]load dataset:  28%|██▊       | 931/3274 [00:01<00:06, 334.75it/s]load dataset:  30%|██▉       | 974/3274 [00:02<00:06, 339.11it/s]load dataset:  31%|███       | 1015/3274 [00:02<00:06, 338.91it/s]load dataset:  33%|███▎      | 1091/3274 [00:02<00:05, 427.58it/s]load dataset:  35%|███▌      | 1155/3274 [00:02<00:04, 476.22it/s]load dataset:  37%|███▋      | 1209/3274 [00:02<00:04, 473.62it/s]load dataset:  39%|███▉      | 1269/3274 [00:02<00:03, 504.56it/s]load dataset:  42%|████▏     | 1362/3274 [00:02<00:03, 617.56it/s]load dataset:  44%|████▎     | 1428/3274 [00:02<00:03, 464.91it/s]load dataset:  45%|████▌     | 1483/3274 [00:03<00:04, 398.74it/s]load dataset:  47%|████▋     | 1530/3274 [00:03<00:05, 335.31it/s]load dataset:  48%|████▊     | 1570/3274 [00:03<00:04, 346.45it/s]load dataset:  49%|████▉     | 1610/3274 [00:03<00:04, 344.63it/s]load dataset:  51%|█████     | 1655/3274 [00:03<00:04, 367.89it/s]load dataset:  52%|█████▏    | 1715/3274 [00:03<00:03, 425.11it/s]load dataset:  54%|█████▍    | 1761/3274 [00:03<00:03, 431.69it/s]load dataset:  55%|█████▌    | 1807/3274 [00:03<00:03, 402.33it/s]load dataset:  57%|█████▋    | 1852/3274 [00:04<00:03, 414.06it/s]load dataset:  58%|█████▊    | 1905/3274 [00:04<00:03, 442.11it/s]load dataset:  60%|█████▉    | 1951/3274 [00:04<00:03, 408.28it/s]load dataset:  62%|██████▏   | 2016/3274 [00:04<00:02, 469.82it/s]load dataset:  63%|██████▎   | 2065/3274 [00:04<00:02, 446.52it/s]load dataset:  64%|██████▍   | 2111/3274 [00:04<00:02, 424.61it/s]load dataset:  66%|██████▌   | 2155/3274 [00:04<00:02, 401.79it/s]load dataset:  67%|██████▋   | 2196/3274 [00:04<00:02, 396.55it/s]load dataset:  68%|██████▊   | 2239/3274 [00:04<00:02, 405.08it/s]load dataset:  70%|██████▉   | 2280/3274 [00:05<00:02, 403.00it/s]load dataset:  71%|███████   | 2322/3274 [00:05<00:02, 406.14it/s]load dataset:  72%|███████▏  | 2367/3274 [00:05<00:02, 415.95it/s]load dataset:  74%|███████▍  | 2416/3274 [00:05<00:01, 436.59it/s]load dataset:  75%|███████▌  | 2460/3274 [00:05<00:01, 435.35it/s]load dataset:  76%|███████▋  | 2504/3274 [00:05<00:02, 373.82it/s]load dataset:  78%|███████▊  | 2561/3274 [00:05<00:01, 414.07it/s]load dataset:  80%|███████▉  | 2611/3274 [00:05<00:01, 436.01it/s]load dataset:  81%|████████  | 2658/3274 [00:05<00:01, 445.19it/s]load dataset:  83%|████████▎ | 2704/3274 [00:06<00:01, 395.12it/s]load dataset:  84%|████████▍ | 2746/3274 [00:06<00:01, 366.64it/s]load dataset:  85%|████████▌ | 2790/3274 [00:06<00:01, 385.19it/s]load dataset:  87%|████████▋ | 2839/3274 [00:06<00:01, 413.07it/s]load dataset:  88%|████████▊ | 2882/3274 [00:06<00:00, 396.33it/s]load dataset:  89%|████████▉ | 2923/3274 [00:06<00:00, 380.44it/s]load dataset:  90%|█████████ | 2962/3274 [00:06<00:00, 373.00it/s]load dataset:  92%|█████████▏| 3000/3274 [00:06<00:00, 348.19it/s]load dataset:  93%|█████████▎| 3036/3274 [00:07<00:00, 335.48it/s]load dataset:  94%|█████████▍| 3073/3274 [00:07<00:00, 343.01it/s]load dataset:  95%|█████████▍| 3108/3274 [00:07<00:00, 293.72it/s]load dataset:  96%|█████████▌| 3139/3274 [00:07<00:00, 280.35it/s]load dataset:  97%|█████████▋| 3168/3274 [00:07<00:00, 246.53it/s]load dataset:  98%|█████████▊| 3194/3274 [00:07<00:00, 205.43it/s]load dataset:  98%|█████████▊| 3217/3274 [00:07<00:00, 205.72it/s]load dataset:  99%|█████████▉| 3246/3274 [00:08<00:00, 220.51it/s]load dataset: 100%|█████████▉| 3270/3274 [00:08<00:00, 188.41it/s]load dataset: 100%|██████████| 3274/3274 [00:08<00:00, 397.75it/s]
12/25/2023 22:45:20 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:45:20 - INFO - __main__ -     Num examples = 3274
12/25/2023 22:45:20 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/7 [00:00<?, ?it/s]evaluate test:  14%|█▍        | 1/7 [00:05<00:30,  5.00s/it]evaluate test:  29%|██▊       | 2/7 [00:08<00:20,  4.06s/it]evaluate test:  43%|████▎     | 3/7 [00:11<00:15,  3.76s/it]evaluate test:  57%|█████▋    | 4/7 [00:15<00:10,  3.62s/it]evaluate test:  71%|███████▏  | 5/7 [00:18<00:07,  3.54s/it]evaluate test:  86%|████████▌ | 6/7 [00:22<00:03,  3.53s/it]evaluate test: 100%|██████████| 7/7 [00:23<00:00,  2.82s/it]evaluate test: 100%|██████████| 7/7 [00:23<00:00,  3.35s/it]
12/25/2023 22:45:44 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:45:44 - INFO - __main__ -     test_accuracy = 0.9844
12/25/2023 22:45:44 - INFO - __main__ -     test_f1 = 0.8339
12/25/2023 22:45:44 - INFO - __main__ -     test_precision = 0.8707
12/25/2023 22:45:44 - INFO - __main__ -     test_recall = 0.8
12/25/2023 22:45:44 - INFO - __main__ -     test_threshold = 0.5

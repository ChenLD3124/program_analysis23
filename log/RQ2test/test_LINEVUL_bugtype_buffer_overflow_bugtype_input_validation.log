12/25/2023 22:30:30 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:30:33 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_buffer_overflow', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_buffer_overflow/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/2551 [00:00<?, ?it/s]load dataset:   3%|▎         | 69/2551 [00:00<00:03, 671.62it/s]load dataset:   5%|▌         | 137/2551 [00:00<00:03, 609.50it/s]load dataset:   8%|▊         | 199/2551 [00:00<00:04, 535.27it/s]load dataset:  10%|▉         | 254/2551 [00:00<00:04, 509.10it/s]load dataset:  13%|█▎        | 330/2551 [00:00<00:03, 588.28it/s]load dataset:  16%|█▌        | 398/2551 [00:00<00:03, 605.54it/s]load dataset:  18%|█▊        | 470/2551 [00:00<00:03, 639.48it/s]load dataset:  21%|██        | 535/2551 [00:00<00:03, 619.12it/s]load dataset:  24%|██▍       | 624/2551 [00:00<00:02, 698.19it/s]load dataset:  27%|██▋       | 695/2551 [00:01<00:02, 700.43it/s]load dataset:  30%|███       | 766/2551 [00:01<00:02, 686.69it/s]load dataset:  33%|███▎      | 836/2551 [00:01<00:02, 670.72it/s]load dataset:  35%|███▌      | 904/2551 [00:01<00:02, 650.30it/s]load dataset:  38%|███▊      | 970/2551 [00:01<00:02, 611.86it/s]load dataset:  40%|████      | 1032/2551 [00:01<00:02, 598.12it/s]load dataset:  43%|████▎     | 1106/2551 [00:01<00:02, 636.98it/s]load dataset:  46%|████▌     | 1171/2551 [00:01<00:02, 574.99it/s]load dataset:  48%|████▊     | 1230/2551 [00:02<00:02, 563.28it/s]load dataset:  50%|█████     | 1288/2551 [00:02<00:02, 454.11it/s]load dataset:  53%|█████▎    | 1364/2551 [00:02<00:02, 526.08it/s]load dataset:  57%|█████▋    | 1443/2551 [00:02<00:01, 588.86it/s]load dataset:  60%|█████▉    | 1519/2551 [00:02<00:01, 633.62it/s]load dataset:  64%|██████▎   | 1620/2551 [00:02<00:01, 733.69it/s]load dataset:  67%|██████▋   | 1713/2551 [00:02<00:01, 781.81it/s]load dataset:  70%|███████   | 1794/2551 [00:02<00:01, 740.13it/s]load dataset:  73%|███████▎  | 1871/2551 [00:02<00:00, 735.50it/s]load dataset:  77%|███████▋  | 1955/2551 [00:03<00:00, 761.43it/s]load dataset:  80%|███████▉  | 2033/2551 [00:03<00:00, 712.20it/s]load dataset:  83%|████████▎ | 2110/2551 [00:03<00:00, 725.90it/s]load dataset:  86%|████████▌ | 2184/2551 [00:03<00:00, 712.57it/s]load dataset:  88%|████████▊ | 2256/2551 [00:03<00:00, 687.00it/s]load dataset:  92%|█████████▏| 2335/2551 [00:03<00:00, 714.15it/s]load dataset:  94%|█████████▍| 2408/2551 [00:03<00:00, 649.48it/s]load dataset:  97%|█████████▋| 2475/2551 [00:04<00:00, 393.15it/s]load dataset:  99%|█████████▉| 2528/2551 [00:04<00:00, 349.58it/s]load dataset: 100%|██████████| 2551/2551 [00:04<00:00, 579.37it/s]
12/25/2023 22:30:41 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:30:41 - INFO - __main__ -     Num examples = 2551
12/25/2023 22:30:41 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/5 [00:00<?, ?it/s]evaluate test:  20%|██        | 1/5 [00:04<00:19,  4.91s/it]evaluate test:  40%|████      | 2/5 [00:08<00:12,  4.00s/it]evaluate test:  60%|██████    | 3/5 [00:11<00:07,  3.73s/it]evaluate test:  80%|████████  | 4/5 [00:15<00:03,  3.58s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.48s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.67s/it]
12/25/2023 22:30:59 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:30:59 - INFO - __main__ -     test_accuracy = 0.9596
12/25/2023 22:30:59 - INFO - __main__ -     test_f1 = 0.6308
12/25/2023 22:30:59 - INFO - __main__ -     test_precision = 0.6197
12/25/2023 22:30:59 - INFO - __main__ -     test_recall = 0.6423
12/25/2023 22:30:59 - INFO - __main__ -     test_threshold = 0.5

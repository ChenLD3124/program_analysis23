12/25/2023 22:56:36 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:56:40 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_resource_allocation_free', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_resource_allocation_free/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3274 [00:00<?, ?it/s]load dataset:   2%|▏         | 51/3274 [00:00<00:06, 495.70it/s]load dataset:   3%|▎         | 101/3274 [00:00<00:06, 497.34it/s]load dataset:   5%|▍         | 156/3274 [00:00<00:06, 519.52it/s]load dataset:   6%|▋         | 208/3274 [00:00<00:07, 434.84it/s]load dataset:   8%|▊         | 269/3274 [00:00<00:06, 480.98it/s]load dataset:  11%|█         | 348/3274 [00:00<00:05, 576.30it/s]load dataset:  13%|█▎        | 426/3274 [00:00<00:04, 632.97it/s]load dataset:  15%|█▍        | 491/3274 [00:00<00:04, 632.81it/s]load dataset:  18%|█▊        | 585/3274 [00:00<00:03, 720.29it/s]load dataset:  21%|██        | 687/3274 [00:01<00:03, 808.68it/s]load dataset:  23%|██▎       | 769/3274 [00:01<00:03, 727.74it/s]load dataset:  26%|██▌       | 852/3274 [00:01<00:03, 755.71it/s]load dataset:  28%|██▊       | 930/3274 [00:01<00:03, 655.77it/s]load dataset:  31%|███       | 1014/3274 [00:01<00:03, 701.34it/s]load dataset:  35%|███▍      | 1140/3274 [00:01<00:02, 850.79it/s]load dataset:  38%|███▊      | 1229/3274 [00:01<00:02, 808.33it/s]load dataset:  41%|████      | 1349/3274 [00:01<00:02, 914.00it/s]load dataset:  44%|████▍     | 1444/3274 [00:02<00:02, 724.45it/s]load dataset:  47%|████▋     | 1525/3274 [00:02<00:02, 680.92it/s]load dataset:  49%|████▉     | 1612/3274 [00:02<00:02, 724.50it/s]load dataset:  52%|█████▏    | 1690/3274 [00:02<00:02, 708.20it/s]load dataset:  54%|█████▍    | 1769/3274 [00:02<00:02, 727.96it/s]load dataset:  56%|█████▋    | 1845/3274 [00:02<00:02, 712.66it/s]load dataset:  59%|█████▉    | 1932/3274 [00:02<00:01, 754.06it/s]load dataset:  62%|██████▏   | 2040/3274 [00:02<00:01, 838.29it/s]load dataset:  65%|██████▍   | 2126/3274 [00:02<00:01, 805.10it/s]load dataset:  67%|██████▋   | 2208/3274 [00:03<00:01, 784.86it/s]load dataset:  70%|██████▉   | 2288/3274 [00:03<00:01, 775.02it/s]load dataset:  73%|███████▎  | 2374/3274 [00:03<00:01, 798.53it/s]load dataset:  75%|███████▌  | 2467/3274 [00:03<00:00, 834.45it/s]load dataset:  78%|███████▊  | 2558/3274 [00:03<00:00, 848.35it/s]load dataset:  81%|████████  | 2644/3274 [00:03<00:00, 849.26it/s]load dataset:  83%|████████▎ | 2730/3274 [00:03<00:00, 750.84it/s]load dataset:  86%|████████▋ | 2826/3274 [00:03<00:00, 805.69it/s]load dataset:  89%|████████▉ | 2909/3274 [00:03<00:00, 795.47it/s]load dataset:  91%|█████████▏| 2991/3274 [00:04<00:00, 728.52it/s]load dataset:  94%|█████████▎| 3066/3274 [00:04<00:00, 693.80it/s]load dataset:  96%|█████████▌| 3137/3274 [00:04<00:00, 613.04it/s]load dataset:  98%|█████████▊| 3201/3274 [00:04<00:00, 523.38it/s]load dataset:  99%|█████████▉| 3257/3274 [00:04<00:00, 446.73it/s]load dataset: 100%|██████████| 3274/3274 [00:04<00:00, 666.13it/s]
12/25/2023 22:56:48 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:56:48 - INFO - __main__ -     Num examples = 3274
12/25/2023 22:56:48 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/7 [00:00<?, ?it/s]evaluate test:  14%|█▍        | 1/7 [00:06<00:40,  6.69s/it]evaluate test:  29%|██▊       | 2/7 [00:10<00:24,  4.85s/it]evaluate test:  43%|████▎     | 3/7 [00:13<00:16,  4.20s/it]evaluate test:  57%|█████▋    | 4/7 [00:17<00:11,  3.89s/it]evaluate test:  71%|███████▏  | 5/7 [00:20<00:07,  3.71s/it]evaluate test:  86%|████████▌ | 6/7 [00:23<00:03,  3.61s/it]evaluate test: 100%|██████████| 7/7 [00:25<00:00,  2.88s/it]evaluate test: 100%|██████████| 7/7 [00:25<00:00,  3.61s/it]
12/25/2023 22:57:13 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:57:13 - INFO - __main__ -     test_accuracy = 0.9771
12/25/2023 22:57:13 - INFO - __main__ -     test_f1 = 0.7387
12/25/2023 22:57:13 - INFO - __main__ -     test_precision = 0.8346
12/25/2023 22:57:13 - INFO - __main__ -     test_recall = 0.6625
12/25/2023 22:57:13 - INFO - __main__ -     test_threshold = 0.5

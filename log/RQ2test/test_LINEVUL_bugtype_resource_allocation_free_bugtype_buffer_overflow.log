12/25/2023 22:52:47 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:52:51 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_resource_allocation_free', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_resource_allocation_free/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3729 [00:00<?, ?it/s]load dataset:   2%|▏         | 56/3729 [00:00<00:06, 551.60it/s]load dataset:   3%|▎         | 127/3729 [00:00<00:05, 624.78it/s]load dataset:   5%|▌         | 190/3729 [00:00<00:06, 580.79it/s]load dataset:   7%|▋         | 249/3729 [00:00<00:06, 512.18it/s]load dataset:   8%|▊         | 306/3729 [00:00<00:06, 527.58it/s]load dataset:  10%|▉         | 370/3729 [00:00<00:06, 556.93it/s]load dataset:  11%|█▏        | 427/3729 [00:00<00:06, 520.85it/s]load dataset:  13%|█▎        | 480/3729 [00:00<00:06, 511.33it/s]load dataset:  14%|█▍        | 538/3729 [00:01<00:06, 529.71it/s]load dataset:  16%|█▌        | 596/3729 [00:01<00:05, 543.11it/s]load dataset:  18%|█▊        | 656/3729 [00:01<00:05, 556.59it/s]load dataset:  20%|█▉        | 733/3729 [00:01<00:04, 611.56it/s]load dataset:  21%|██▏       | 795/3729 [00:01<00:05, 561.39it/s]load dataset:  23%|██▎       | 853/3729 [00:01<00:05, 549.76it/s]load dataset:  24%|██▍       | 909/3729 [00:01<00:05, 512.20it/s]load dataset:  26%|██▌       | 977/3729 [00:01<00:04, 552.89it/s]load dataset:  28%|██▊       | 1039/3729 [00:01<00:04, 569.70it/s]load dataset:  29%|██▉       | 1097/3729 [00:02<00:05, 469.09it/s]load dataset:  31%|███       | 1161/3729 [00:02<00:05, 507.75it/s]load dataset:  33%|███▎      | 1235/3729 [00:02<00:04, 562.51it/s]load dataset:  35%|███▍      | 1295/3729 [00:02<00:04, 516.86it/s]load dataset:  36%|███▌      | 1350/3729 [00:02<00:04, 507.65it/s]load dataset:  38%|███▊      | 1403/3729 [00:02<00:05, 418.51it/s]load dataset:  39%|███▉      | 1449/3729 [00:02<00:05, 403.99it/s]load dataset:  40%|████      | 1492/3729 [00:02<00:05, 404.15it/s]load dataset:  41%|████      | 1534/3729 [00:03<00:06, 317.03it/s]load dataset:  43%|████▎     | 1594/3729 [00:03<00:05, 378.80it/s]load dataset:  45%|████▍     | 1672/3729 [00:03<00:04, 473.59it/s]load dataset:  47%|████▋     | 1768/3729 [00:03<00:03, 590.71it/s]load dataset:  50%|████▉     | 1856/3729 [00:03<00:02, 662.52it/s]load dataset:  52%|█████▏    | 1928/3729 [00:03<00:03, 596.91it/s]load dataset:  53%|█████▎    | 1993/3729 [00:03<00:03, 565.65it/s]load dataset:  55%|█████▌    | 2053/3729 [00:04<00:03, 466.40it/s]load dataset:  57%|█████▋    | 2124/3729 [00:04<00:03, 519.97it/s]load dataset:  59%|█████▉    | 2195/3729 [00:04<00:02, 558.72it/s]load dataset:  61%|██████    | 2263/3729 [00:04<00:02, 589.60it/s]load dataset:  62%|██████▏   | 2326/3729 [00:04<00:02, 577.62it/s]load dataset:  65%|██████▍   | 2411/3729 [00:04<00:02, 643.05it/s]load dataset:  67%|██████▋   | 2480/3729 [00:04<00:01, 655.44it/s]load dataset:  68%|██████▊   | 2548/3729 [00:04<00:01, 627.21it/s]load dataset:  70%|███████   | 2626/3729 [00:04<00:01, 668.43it/s]load dataset:  72%|███████▏  | 2695/3729 [00:04<00:01, 666.49it/s]load dataset:  75%|███████▍  | 2781/3729 [00:05<00:01, 714.34it/s]load dataset:  77%|███████▋  | 2857/3729 [00:05<00:01, 724.41it/s]load dataset:  79%|███████▉  | 2939/3729 [00:05<00:01, 749.96it/s]load dataset:  81%|████████  | 3015/3729 [00:05<00:00, 716.13it/s]load dataset:  83%|████████▎ | 3088/3729 [00:05<00:01, 638.87it/s]load dataset:  85%|████████▍ | 3154/3729 [00:05<00:00, 588.95it/s]load dataset:  86%|████████▌ | 3215/3729 [00:05<00:00, 559.71it/s]load dataset:  88%|████████▊ | 3273/3729 [00:05<00:00, 496.71it/s]load dataset:  89%|████████▉ | 3332/3729 [00:06<00:00, 508.84it/s]load dataset:  91%|█████████ | 3385/3729 [00:06<00:00, 473.91it/s]load dataset:  93%|█████████▎| 3454/3729 [00:06<00:00, 526.14it/s]load dataset:  94%|█████████▍| 3509/3729 [00:06<00:00, 404.58it/s]load dataset:  95%|█████████▌| 3555/3729 [00:06<00:00, 315.39it/s]load dataset:  96%|█████████▋| 3593/3729 [00:07<00:00, 196.06it/s]load dataset:  97%|█████████▋| 3622/3729 [00:07<00:00, 159.36it/s]load dataset:  98%|█████████▊| 3646/3729 [00:07<00:00, 165.92it/s]load dataset:  98%|█████████▊| 3669/3729 [00:07<00:00, 173.46it/s]load dataset:  99%|█████████▉| 3691/3729 [00:07<00:00, 173.03it/s]load dataset: 100%|██████████| 3729/3729 [00:07<00:00, 467.66it/s]
12/25/2023 22:53:06 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:53:06 - INFO - __main__ -     Num examples = 3729
12/25/2023 22:53:06 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/8 [00:00<?, ?it/s]evaluate test:  12%|█▎        | 1/8 [00:05<00:37,  5.36s/it]evaluate test:  25%|██▌       | 2/8 [00:08<00:25,  4.21s/it]evaluate test:  38%|███▊      | 3/8 [00:12<00:19,  3.86s/it]evaluate test:  50%|█████     | 4/8 [00:15<00:14,  3.70s/it]evaluate test:  62%|██████▎   | 5/8 [00:19<00:10,  3.59s/it]evaluate test:  75%|███████▌  | 6/8 [00:22<00:07,  3.51s/it]evaluate test:  88%|████████▊ | 7/8 [00:25<00:03,  3.48s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  2.69s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  3.35s/it]
12/25/2023 22:53:33 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:53:33 - INFO - __main__ -     test_accuracy = 0.9657
12/25/2023 22:53:33 - INFO - __main__ -     test_f1 = 0.7409
12/25/2023 22:53:33 - INFO - __main__ -     test_precision = 0.8551
12/25/2023 22:53:33 - INFO - __main__ -     test_recall = 0.6536
12/25/2023 22:53:33 - INFO - __main__ -     test_threshold = 0.5

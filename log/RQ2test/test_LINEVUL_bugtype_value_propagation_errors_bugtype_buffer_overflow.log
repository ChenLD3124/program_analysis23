12/25/2023 22:58:32 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:58:36 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_value_propagation_errors', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_value_propagation_errors/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3729 [00:00<?, ?it/s]load dataset:   2%|▏         | 56/3729 [00:00<00:06, 553.27it/s]load dataset:   3%|▎         | 127/3729 [00:00<00:05, 636.93it/s]load dataset:   5%|▌         | 191/3729 [00:00<00:05, 596.67it/s]load dataset:   7%|▋         | 251/3729 [00:00<00:06, 533.46it/s]load dataset:   8%|▊         | 306/3729 [00:00<00:06, 536.79it/s]load dataset:  10%|▉         | 370/3729 [00:00<00:05, 564.32it/s]load dataset:  12%|█▏        | 432/3729 [00:00<00:05, 576.45it/s]load dataset:  13%|█▎        | 498/3729 [00:00<00:05, 600.46it/s]load dataset:  15%|█▌        | 562/3729 [00:00<00:05, 611.08it/s]load dataset:  17%|█▋        | 624/3729 [00:01<00:05, 602.81it/s]load dataset:  18%|█▊        | 685/3729 [00:01<00:05, 587.36it/s]load dataset:  20%|██        | 749/3729 [00:01<00:04, 602.42it/s]load dataset:  22%|██▏       | 810/3729 [00:01<00:04, 584.55it/s]load dataset:  23%|██▎       | 869/3729 [00:01<00:04, 572.38it/s]load dataset:  25%|██▍       | 927/3729 [00:01<00:05, 532.76it/s]load dataset:  27%|██▋       | 992/3729 [00:01<00:04, 564.84it/s]load dataset:  28%|██▊       | 1050/3729 [00:01<00:04, 564.54it/s]load dataset:  30%|██▉       | 1107/3729 [00:01<00:05, 473.74it/s]load dataset:  31%|███▏      | 1167/3729 [00:02<00:05, 505.31it/s]load dataset:  33%|███▎      | 1237/3729 [00:02<00:04, 553.34it/s]load dataset:  35%|███▍      | 1295/3729 [00:02<00:04, 510.75it/s]load dataset:  36%|███▌      | 1349/3729 [00:02<00:04, 504.15it/s]load dataset:  38%|███▊      | 1401/3729 [00:02<00:05, 420.79it/s]load dataset:  39%|███▉      | 1447/3729 [00:02<00:05, 402.22it/s]load dataset:  40%|███▉      | 1490/3729 [00:02<00:05, 399.87it/s]load dataset:  41%|████      | 1532/3729 [00:03<00:07, 313.78it/s]load dataset:  43%|████▎     | 1590/3729 [00:03<00:05, 372.01it/s]load dataset:  45%|████▍     | 1664/3729 [00:03<00:04, 459.10it/s]load dataset:  47%|████▋     | 1764/3729 [00:03<00:03, 593.50it/s]load dataset:  50%|████▉     | 1846/3729 [00:03<00:02, 652.60it/s]load dataset:  51%|█████▏    | 1917/3729 [00:03<00:03, 590.37it/s]load dataset:  53%|█████▎    | 1981/3729 [00:03<00:03, 562.39it/s]load dataset:  55%|█████▍    | 2041/3729 [00:03<00:03, 464.37it/s]load dataset:  57%|█████▋    | 2115/3729 [00:04<00:03, 527.26it/s]load dataset:  59%|█████▊    | 2187/3729 [00:04<00:02, 572.49it/s]load dataset:  60%|██████    | 2249/3729 [00:04<00:02, 580.04it/s]load dataset:  62%|██████▏   | 2315/3729 [00:04<00:02, 577.78it/s]load dataset:  64%|██████▍   | 2399/3729 [00:04<00:02, 648.08it/s]load dataset:  66%|██████▌   | 2467/3729 [00:04<00:01, 645.38it/s]load dataset:  68%|██████▊   | 2534/3729 [00:04<00:01, 606.20it/s]load dataset:  70%|██████▉   | 2610/3729 [00:04<00:01, 645.64it/s]load dataset:  72%|███████▏  | 2691/3729 [00:04<00:01, 688.08it/s]load dataset:  75%|███████▍  | 2784/3729 [00:05<00:01, 754.71it/s]load dataset:  77%|███████▋  | 2864/3729 [00:05<00:01, 764.30it/s]load dataset:  79%|███████▉  | 2958/3729 [00:05<00:00, 810.99it/s]load dataset:  82%|████████▏ | 3040/3729 [00:05<00:00, 797.80it/s]load dataset:  84%|████████▎ | 3121/3729 [00:05<00:00, 774.80it/s]load dataset:  86%|████████▌ | 3199/3729 [00:05<00:00, 727.07it/s]load dataset:  88%|████████▊ | 3273/3729 [00:05<00:00, 628.59it/s]load dataset:  90%|████████▉ | 3339/3729 [00:05<00:00, 619.60it/s]load dataset:  91%|█████████▏| 3403/3729 [00:05<00:00, 567.21it/s]load dataset:  93%|█████████▎| 3462/3729 [00:06<00:00, 508.03it/s]load dataset:  94%|█████████▍| 3515/3729 [00:06<00:00, 397.63it/s]load dataset:  95%|█████████▌| 3560/3729 [00:06<00:00, 276.85it/s]load dataset:  96%|█████████▋| 3596/3729 [00:06<00:00, 246.59it/s]load dataset:  97%|█████████▋| 3626/3729 [00:06<00:00, 241.68it/s]load dataset:  98%|█████████▊| 3656/3729 [00:07<00:00, 252.02it/s]load dataset:  99%|█████████▉| 3685/3729 [00:07<00:00, 252.30it/s]load dataset: 100%|█████████▉| 3713/3729 [00:07<00:00, 255.49it/s]load dataset: 100%|██████████| 3729/3729 [00:07<00:00, 508.19it/s]
12/25/2023 22:58:51 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:58:51 - INFO - __main__ -     Num examples = 3729
12/25/2023 22:58:51 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/8 [00:00<?, ?it/s]evaluate test:  12%|█▎        | 1/8 [00:04<00:32,  4.60s/it]evaluate test:  25%|██▌       | 2/8 [00:07<00:23,  3.88s/it]evaluate test:  38%|███▊      | 3/8 [00:11<00:18,  3.67s/it]evaluate test:  50%|█████     | 4/8 [00:14<00:14,  3.57s/it]evaluate test:  62%|██████▎   | 5/8 [00:18<00:10,  3.58s/it]evaluate test:  75%|███████▌  | 6/8 [00:22<00:07,  3.63s/it]evaluate test:  88%|████████▊ | 7/8 [00:25<00:03,  3.56s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  2.74s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  3.32s/it]
12/25/2023 22:59:18 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:59:18 - INFO - __main__ -     test_accuracy = 0.9649
12/25/2023 22:59:18 - INFO - __main__ -     test_f1 = 0.7265
12/25/2023 22:59:18 - INFO - __main__ -     test_precision = 0.8744
12/25/2023 22:59:18 - INFO - __main__ -     test_recall = 0.6214
12/25/2023 22:59:18 - INFO - __main__ -     test_threshold = 0.5

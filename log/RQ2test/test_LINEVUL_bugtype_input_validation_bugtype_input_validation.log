12/25/2023 22:36:08 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:36:13 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_input_validation', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_input_validation/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/2551 [00:00<?, ?it/s]load dataset:   3%|▎         | 69/2551 [00:00<00:03, 682.51it/s]load dataset:   5%|▌         | 138/2551 [00:00<00:03, 614.35it/s]load dataset:   8%|▊         | 200/2551 [00:00<00:04, 551.54it/s]load dataset:  10%|█         | 256/2551 [00:00<00:04, 525.78it/s]load dataset:  13%|█▎        | 328/2551 [00:00<00:03, 587.55it/s]load dataset:  16%|█▌        | 398/2551 [00:00<00:03, 610.82it/s]load dataset:  18%|█▊        | 470/2551 [00:00<00:03, 644.23it/s]load dataset:  21%|██        | 536/2551 [00:00<00:03, 618.82it/s]load dataset:  25%|██▍       | 628/2551 [00:00<00:02, 705.78it/s]load dataset:  27%|██▋       | 700/2551 [00:01<00:02, 709.38it/s]load dataset:  30%|███       | 772/2551 [00:01<00:02, 687.84it/s]load dataset:  33%|███▎      | 842/2551 [00:01<00:02, 674.59it/s]load dataset:  36%|███▌      | 910/2551 [00:01<00:02, 664.82it/s]load dataset:  38%|███▊      | 977/2551 [00:01<00:02, 589.06it/s]load dataset:  41%|████      | 1038/2551 [00:01<00:02, 592.85it/s]load dataset:  44%|████▎     | 1114/2551 [00:01<00:02, 638.71it/s]load dataset:  46%|████▋     | 1180/2551 [00:01<00:02, 579.48it/s]load dataset:  49%|████▊     | 1240/2551 [00:02<00:02, 559.97it/s]load dataset:  51%|█████     | 1298/2551 [00:02<00:02, 461.42it/s]load dataset:  54%|█████▍    | 1379/2551 [00:02<00:02, 542.84it/s]load dataset:  57%|█████▋    | 1448/2551 [00:02<00:01, 575.87it/s]load dataset:  60%|██████    | 1539/2551 [00:02<00:01, 663.71it/s]load dataset:  64%|██████▍   | 1631/2551 [00:02<00:01, 733.40it/s]load dataset:  68%|██████▊   | 1734/2551 [00:02<00:01, 810.17it/s]load dataset:  71%|███████▏  | 1818/2551 [00:02<00:01, 731.69it/s]load dataset:  75%|███████▍  | 1904/2551 [00:02<00:00, 760.45it/s]load dataset:  78%|███████▊  | 1983/2551 [00:03<00:00, 756.77it/s]load dataset:  81%|████████  | 2061/2551 [00:03<00:00, 758.86it/s]load dataset:  84%|████████▍ | 2139/2551 [00:03<00:00, 707.29it/s]load dataset:  87%|████████▋ | 2218/2551 [00:03<00:00, 728.47it/s]load dataset:  90%|████████▉ | 2293/2551 [00:03<00:00, 722.23it/s]load dataset:  93%|█████████▎| 2377/2551 [00:03<00:00, 749.42it/s]load dataset:  96%|█████████▌| 2453/2551 [00:03<00:00, 500.98it/s]load dataset:  99%|█████████▊| 2515/2551 [00:04<00:00, 352.74it/s]load dataset: 100%|██████████| 2551/2551 [00:04<00:00, 586.86it/s]
12/25/2023 22:36:21 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:36:21 - INFO - __main__ -     Num examples = 2551
12/25/2023 22:36:21 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/5 [00:00<?, ?it/s]evaluate test:  20%|██        | 1/5 [00:04<00:18,  4.69s/it]evaluate test:  40%|████      | 2/5 [00:08<00:11,  3.92s/it]evaluate test:  60%|██████    | 3/5 [00:11<00:07,  3.67s/it]evaluate test:  80%|████████  | 4/5 [00:14<00:03,  3.55s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.47s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.63s/it]
12/25/2023 22:36:39 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:36:39 - INFO - __main__ -     test_accuracy = 0.9812
12/25/2023 22:36:39 - INFO - __main__ -     test_f1 = 0.8065
12/25/2023 22:36:39 - INFO - __main__ -     test_precision = 0.9009
12/25/2023 22:36:39 - INFO - __main__ -     test_recall = 0.7299
12/25/2023 22:36:39 - INFO - __main__ -     test_threshold = 0.5

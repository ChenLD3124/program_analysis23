12/25/2023 22:42:06 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:42:10 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_mixed', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_mixed/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/2551 [00:00<?, ?it/s]load dataset:   2%|▏         | 63/2551 [00:00<00:04, 618.70it/s]load dataset:   5%|▍         | 125/2551 [00:00<00:04, 534.24it/s]load dataset:   7%|▋         | 180/2551 [00:00<00:04, 527.16it/s]load dataset:   9%|▉         | 238/2551 [00:00<00:04, 544.94it/s]load dataset:  11%|█▏        | 293/2551 [00:00<00:04, 521.20it/s]load dataset:  15%|█▍        | 372/2551 [00:00<00:03, 605.82it/s]load dataset:  17%|█▋        | 434/2551 [00:00<00:03, 574.83it/s]load dataset:  20%|██        | 512/2551 [00:00<00:03, 634.45it/s]load dataset:  23%|██▎       | 586/2551 [00:00<00:02, 661.37it/s]load dataset:  26%|██▌       | 660/2551 [00:01<00:02, 683.09it/s]load dataset:  29%|██▊       | 729/2551 [00:01<00:02, 674.85it/s]load dataset:  32%|███▏      | 804/2551 [00:01<00:02, 691.62it/s]load dataset:  34%|███▍      | 874/2551 [00:01<00:02, 639.93it/s]load dataset:  37%|███▋      | 942/2551 [00:01<00:02, 647.50it/s]load dataset:  40%|███▉      | 1008/2551 [00:01<00:02, 615.27it/s]load dataset:  42%|████▏     | 1071/2551 [00:01<00:02, 583.68it/s]load dataset:  44%|████▍     | 1131/2551 [00:01<00:02, 586.43it/s]load dataset:  47%|████▋     | 1191/2551 [00:01<00:02, 568.96it/s]load dataset:  49%|████▉     | 1249/2551 [00:02<00:02, 564.66it/s]load dataset:  51%|█████     | 1306/2551 [00:02<00:02, 458.60it/s]load dataset:  54%|█████▍    | 1388/2551 [00:02<00:02, 539.46it/s]load dataset:  57%|█████▋    | 1460/2551 [00:02<00:01, 584.87it/s]load dataset:  61%|██████    | 1551/2551 [00:02<00:01, 671.85it/s]load dataset:  64%|██████▍   | 1643/2551 [00:02<00:01, 740.37it/s]load dataset:  68%|██████▊   | 1736/2551 [00:02<00:01, 793.48it/s]load dataset:  71%|███████▏  | 1818/2551 [00:02<00:01, 646.60it/s]load dataset:  74%|███████▍  | 1889/2551 [00:03<00:01, 643.12it/s]load dataset:  77%|███████▋  | 1963/2551 [00:03<00:00, 664.20it/s]load dataset:  80%|███████▉  | 2033/2551 [00:03<00:00, 670.22it/s]load dataset:  83%|████████▎ | 2109/2551 [00:03<00:00, 694.04it/s]load dataset:  85%|████████▌ | 2181/2551 [00:03<00:00, 691.60it/s]load dataset:  88%|████████▊ | 2252/2551 [00:03<00:00, 667.78it/s]load dataset:  91%|█████████▏| 2334/2551 [00:03<00:00, 706.74it/s]load dataset:  94%|█████████▍| 2406/2551 [00:03<00:00, 550.96it/s]load dataset:  97%|█████████▋| 2467/2551 [00:04<00:00, 390.39it/s]load dataset:  99%|█████████▊| 2516/2551 [00:04<00:00, 322.87it/s]load dataset: 100%|██████████| 2551/2551 [00:04<00:00, 560.28it/s]
12/25/2023 22:42:21 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:42:21 - INFO - __main__ -     Num examples = 2551
12/25/2023 22:42:21 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/5 [00:00<?, ?it/s]evaluate test:  20%|██        | 1/5 [00:04<00:19,  4.88s/it]evaluate test:  40%|████      | 2/5 [00:08<00:12,  4.01s/it]evaluate test:  60%|██████    | 3/5 [00:11<00:07,  3.73s/it]evaluate test:  80%|████████  | 4/5 [00:15<00:03,  3.59s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.50s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.68s/it]
12/25/2023 22:42:39 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:42:39 - INFO - __main__ -     test_accuracy = 0.9828
12/25/2023 22:42:39 - INFO - __main__ -     test_f1 = 0.8333
12/25/2023 22:42:39 - INFO - __main__ -     test_precision = 0.8661
12/25/2023 22:42:39 - INFO - __main__ -     test_recall = 0.8029
12/25/2023 22:42:39 - INFO - __main__ -     test_threshold = 0.5

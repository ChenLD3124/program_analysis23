12/25/2023 22:59:23 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:59:27 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_value_propagation_errors', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_value_propagation_errors/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/2551 [00:00<?, ?it/s]load dataset:   3%|▎         | 69/2551 [00:00<00:03, 686.93it/s]load dataset:   5%|▌         | 138/2551 [00:00<00:03, 630.87it/s]load dataset:   8%|▊         | 202/2551 [00:00<00:04, 566.08it/s]load dataset:  10%|█         | 260/2551 [00:00<00:04, 529.14it/s]load dataset:  13%|█▎        | 344/2551 [00:00<00:03, 628.68it/s]load dataset:  16%|█▌        | 409/2551 [00:00<00:03, 599.05it/s]load dataset:  19%|█▉        | 488/2551 [00:00<00:03, 655.45it/s]load dataset:  22%|██▏       | 555/2551 [00:00<00:03, 659.17it/s]load dataset:  25%|██▌       | 639/2551 [00:00<00:02, 712.92it/s]load dataset:  28%|██▊       | 712/2551 [00:01<00:02, 716.57it/s]load dataset:  31%|███       | 785/2551 [00:01<00:03, 510.45it/s]load dataset:  33%|███▎      | 845/2551 [00:01<00:04, 349.64it/s]load dataset:  35%|███▌      | 893/2551 [00:01<00:05, 308.97it/s]load dataset:  37%|███▋      | 933/2551 [00:02<00:05, 302.80it/s]load dataset:  38%|███▊      | 970/2551 [00:02<00:05, 274.09it/s]load dataset:  40%|███▉      | 1010/2551 [00:02<00:05, 295.26it/s]load dataset:  41%|████      | 1044/2551 [00:02<00:05, 291.19it/s]load dataset:  42%|████▏     | 1078/2551 [00:02<00:04, 301.90it/s]load dataset:  44%|████▎     | 1116/2551 [00:02<00:04, 320.32it/s]load dataset:  45%|████▌     | 1151/2551 [00:02<00:04, 282.02it/s]load dataset:  46%|████▋     | 1183/2551 [00:02<00:04, 287.00it/s]load dataset:  48%|████▊     | 1214/2551 [00:03<00:05, 250.17it/s]load dataset:  49%|████▉     | 1254/2551 [00:03<00:04, 276.05it/s]load dataset:  50%|█████     | 1284/2551 [00:03<00:06, 189.51it/s]load dataset:  52%|█████▏    | 1321/2551 [00:03<00:05, 223.62it/s]load dataset:  53%|█████▎    | 1349/2551 [00:03<00:05, 233.07it/s]load dataset:  54%|█████▍    | 1390/2551 [00:03<00:04, 269.47it/s]load dataset:  56%|█████▌    | 1434/2551 [00:03<00:03, 311.04it/s]load dataset:  58%|█████▊    | 1469/2551 [00:03<00:03, 316.47it/s]load dataset:  60%|██████    | 1532/2551 [00:04<00:02, 399.76it/s]load dataset:  63%|██████▎   | 1596/2551 [00:04<00:02, 462.43it/s]load dataset:  66%|██████▌   | 1671/2551 [00:04<00:01, 540.16it/s]load dataset:  68%|██████▊   | 1727/2551 [00:04<00:01, 513.52it/s]load dataset:  70%|██████▉   | 1780/2551 [00:04<00:01, 403.15it/s]load dataset:  72%|███████▏  | 1825/2551 [00:04<00:01, 397.60it/s]load dataset:  73%|███████▎  | 1869/2551 [00:04<00:01, 407.02it/s]load dataset:  75%|███████▌  | 1919/2551 [00:04<00:01, 428.10it/s]load dataset:  78%|███████▊  | 1992/2551 [00:05<00:01, 501.36it/s]load dataset:  81%|████████  | 2065/2551 [00:05<00:00, 559.82it/s]load dataset:  84%|████████▎ | 2133/2551 [00:05<00:00, 593.05it/s]load dataset:  86%|████████▋ | 2205/2551 [00:05<00:00, 627.01it/s]load dataset:  89%|████████▉ | 2273/2551 [00:05<00:00, 641.31it/s]load dataset:  93%|█████████▎| 2374/2551 [00:05<00:00, 745.06it/s]load dataset:  96%|█████████▌| 2450/2551 [00:05<00:00, 488.20it/s]load dataset:  98%|█████████▊| 2511/2551 [00:06<00:00, 342.37it/s]load dataset: 100%|██████████| 2551/2551 [00:06<00:00, 403.91it/s]
12/25/2023 22:59:37 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:59:37 - INFO - __main__ -     Num examples = 2551
12/25/2023 22:59:37 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/5 [00:00<?, ?it/s]evaluate test:  20%|██        | 1/5 [00:06<00:25,  6.36s/it]evaluate test:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]evaluate test:  60%|██████    | 3/5 [00:13<00:08,  4.07s/it]evaluate test:  80%|████████  | 4/5 [00:16<00:03,  3.80s/it]evaluate test: 100%|██████████| 5/5 [00:19<00:00,  3.64s/it]evaluate test: 100%|██████████| 5/5 [00:19<00:00,  3.99s/it]
12/25/2023 22:59:57 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:59:57 - INFO - __main__ -     test_accuracy = 0.9749
12/25/2023 22:59:57 - INFO - __main__ -     test_f1 = 0.7143
12/25/2023 22:59:57 - INFO - __main__ -     test_precision = 0.9195
12/25/2023 22:59:57 - INFO - __main__ -     test_recall = 0.5839
12/25/2023 22:59:57 - INFO - __main__ -     test_threshold = 0.5

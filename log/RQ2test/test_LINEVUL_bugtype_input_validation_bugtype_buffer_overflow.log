12/25/2023 22:35:18 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:35:21 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_input_validation', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_input_validation/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3729 [00:00<?, ?it/s]load dataset:   2%|▏         | 56/3729 [00:00<00:06, 548.20it/s]load dataset:   3%|▎         | 125/3729 [00:00<00:05, 627.96it/s]load dataset:   5%|▌         | 188/3729 [00:00<00:06, 574.14it/s]load dataset:   7%|▋         | 246/3729 [00:00<00:06, 503.82it/s]load dataset:   8%|▊         | 302/3729 [00:00<00:06, 518.45it/s]load dataset:  10%|▉         | 365/3729 [00:00<00:06, 542.54it/s]load dataset:  11%|█▏        | 423/3729 [00:00<00:05, 552.60it/s]load dataset:  13%|█▎        | 492/3729 [00:00<00:05, 591.90it/s]load dataset:  15%|█▍        | 552/3729 [00:00<00:05, 589.52it/s]load dataset:  16%|█▋        | 612/3729 [00:01<00:05, 573.55it/s]load dataset:  18%|█▊        | 670/3729 [00:01<00:05, 569.69it/s]load dataset:  20%|█▉        | 744/3729 [00:01<00:04, 618.66it/s]load dataset:  22%|██▏       | 807/3729 [00:01<00:05, 576.25it/s]load dataset:  23%|██▎       | 866/3729 [00:01<00:05, 571.00it/s]load dataset:  25%|██▍       | 924/3729 [00:01<00:05, 534.41it/s]load dataset:  26%|██▋       | 987/3729 [00:01<00:04, 559.86it/s]load dataset:  28%|██▊       | 1044/3729 [00:01<00:04, 562.47it/s]load dataset:  30%|██▉       | 1101/3729 [00:02<00:05, 467.75it/s]load dataset:  31%|███       | 1161/3729 [00:02<00:05, 500.19it/s]load dataset:  33%|███▎      | 1234/3729 [00:02<00:04, 558.64it/s]load dataset:  35%|███▍      | 1293/3729 [00:02<00:04, 502.39it/s]load dataset:  36%|███▌      | 1346/3729 [00:02<00:04, 493.88it/s]load dataset:  37%|███▋      | 1398/3729 [00:02<00:05, 420.59it/s]load dataset:  39%|███▊      | 1443/3729 [00:02<00:05, 391.49it/s]load dataset:  40%|███▉      | 1485/3729 [00:02<00:05, 389.16it/s]load dataset:  41%|████      | 1528/3729 [00:03<00:09, 221.76it/s]load dataset:  42%|████▏     | 1560/3729 [00:03<00:10, 211.54it/s]load dataset:  43%|████▎     | 1588/3729 [00:03<00:10, 204.97it/s]load dataset:  43%|████▎     | 1613/3729 [00:03<00:10, 204.39it/s]load dataset:  44%|████▍     | 1637/3729 [00:03<00:10, 206.13it/s]load dataset:  46%|████▌     | 1702/3729 [00:03<00:06, 302.08it/s]load dataset:  47%|████▋     | 1760/3729 [00:04<00:05, 365.03it/s]load dataset:  49%|████▉     | 1818/3729 [00:04<00:04, 417.97it/s]load dataset:  50%|█████     | 1865/3729 [00:04<00:04, 415.10it/s]load dataset:  51%|█████     | 1910/3729 [00:04<00:04, 366.88it/s]load dataset:  52%|█████▏    | 1951/3729 [00:04<00:04, 371.19it/s]load dataset:  53%|█████▎    | 1991/3729 [00:04<00:04, 352.18it/s]load dataset:  54%|█████▍    | 2028/3729 [00:04<00:05, 301.75it/s]load dataset:  55%|█████▌    | 2061/3729 [00:05<00:06, 270.73it/s]load dataset:  57%|█████▋    | 2129/3729 [00:05<00:04, 363.79it/s]load dataset:  59%|█████▉    | 2195/3729 [00:05<00:03, 432.66it/s]load dataset:  61%|██████    | 2262/3729 [00:05<00:02, 491.75it/s]load dataset:  62%|██████▏   | 2315/3729 [00:05<00:02, 495.12it/s]load dataset:  64%|██████▍   | 2399/3729 [00:05<00:02, 588.20it/s]load dataset:  66%|██████▌   | 2461/3729 [00:05<00:02, 592.95it/s]load dataset:  68%|██████▊   | 2523/3729 [00:05<00:02, 551.88it/s]load dataset:  70%|██████▉   | 2594/3729 [00:05<00:01, 594.30it/s]load dataset:  72%|███████▏  | 2672/3729 [00:05<00:01, 643.58it/s]load dataset:  74%|███████▍  | 2762/3729 [00:06<00:01, 714.97it/s]load dataset:  76%|███████▌  | 2835/3729 [00:06<00:01, 687.61it/s]load dataset:  79%|███████▊  | 2935/3729 [00:06<00:01, 774.51it/s]load dataset:  81%|████████  | 3018/3729 [00:06<00:00, 786.76it/s]load dataset:  83%|████████▎ | 3098/3729 [00:06<00:00, 728.27it/s]load dataset:  85%|████████▌ | 3173/3729 [00:06<00:00, 702.71it/s]load dataset:  87%|████████▋ | 3245/3729 [00:06<00:00, 617.87it/s]load dataset:  89%|████████▉ | 3310/3729 [00:06<00:00, 618.74it/s]load dataset:  90%|█████████ | 3374/3729 [00:07<00:00, 551.77it/s]load dataset:  92%|█████████▏| 3432/3729 [00:07<00:00, 547.42it/s]load dataset:  94%|█████████▎| 3489/3729 [00:07<00:00, 450.29it/s]load dataset:  95%|█████████▍| 3538/3729 [00:07<00:00, 348.57it/s]load dataset:  96%|█████████▌| 3579/3729 [00:07<00:00, 271.08it/s]load dataset:  97%|█████████▋| 3612/3729 [00:08<00:00, 246.49it/s]load dataset:  98%|█████████▊| 3646/3729 [00:08<00:00, 260.77it/s]load dataset:  99%|█████████▊| 3676/3729 [00:08<00:00, 263.94it/s]load dataset:  99%|█████████▉| 3705/3729 [00:08<00:00, 242.18it/s]load dataset: 100%|██████████| 3729/3729 [00:08<00:00, 442.33it/s]
12/25/2023 22:35:37 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:35:37 - INFO - __main__ -     Num examples = 3729
12/25/2023 22:35:37 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/8 [00:00<?, ?it/s]evaluate test:  12%|█▎        | 1/8 [00:04<00:32,  4.70s/it]evaluate test:  25%|██▌       | 2/8 [00:08<00:23,  3.94s/it]evaluate test:  38%|███▊      | 3/8 [00:11<00:18,  3.70s/it]evaluate test:  50%|█████     | 4/8 [00:14<00:14,  3.58s/it]evaluate test:  62%|██████▎   | 5/8 [00:18<00:10,  3.51s/it]evaluate test:  75%|███████▌  | 6/8 [00:21<00:06,  3.46s/it]evaluate test:  88%|████████▊ | 7/8 [00:25<00:03,  3.44s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  2.66s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  3.26s/it]
12/25/2023 22:36:03 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:36:03 - INFO - __main__ -     test_accuracy = 0.9638
12/25/2023 22:36:03 - INFO - __main__ -     test_f1 = 0.7239
12/25/2023 22:36:03 - INFO - __main__ -     test_precision = 0.8469
12/25/2023 22:36:03 - INFO - __main__ -     test_recall = 0.6321
12/25/2023 22:36:03 - INFO - __main__ -     test_threshold = 0.5

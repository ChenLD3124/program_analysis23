12/25/2023 23:02:20 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 23:02:24 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_value_propagation_errors', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_privilege_escalation_authorization/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_value_propagation_errors/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3274 [00:00<?, ?it/s]load dataset:   2%|▏         | 50/3274 [00:00<00:06, 488.11it/s]load dataset:   3%|▎         | 99/3274 [00:00<00:06, 484.90it/s]load dataset:   5%|▍         | 154/3274 [00:00<00:06, 495.86it/s]load dataset:   6%|▌         | 204/3274 [00:00<00:07, 436.57it/s]load dataset:   8%|▊         | 263/3274 [00:00<00:06, 485.28it/s]load dataset:  10%|▉         | 316/3274 [00:00<00:05, 498.92it/s]load dataset:  12%|█▏        | 404/3274 [00:00<00:04, 616.97it/s]load dataset:  14%|█▍        | 467/3274 [00:00<00:04, 574.11it/s]load dataset:  17%|█▋        | 567/3274 [00:00<00:03, 695.54it/s]load dataset:  20%|██        | 664/3274 [00:01<00:03, 771.71it/s]load dataset:  23%|██▎       | 743/3274 [00:01<00:03, 726.09it/s]load dataset:  25%|██▌       | 822/3274 [00:01<00:03, 738.13it/s]load dataset:  27%|██▋       | 897/3274 [00:01<00:03, 679.01it/s]load dataset:  30%|██▉       | 967/3274 [00:01<00:03, 672.59it/s]load dataset:  33%|███▎      | 1084/3274 [00:01<00:02, 808.97it/s]load dataset:  36%|███▌      | 1174/3274 [00:01<00:02, 825.91it/s]load dataset:  38%|███▊      | 1259/3274 [00:01<00:02, 801.83it/s]load dataset:  42%|████▏     | 1369/3274 [00:01<00:02, 881.81it/s]load dataset:  45%|████▍     | 1459/3274 [00:02<00:02, 711.89it/s]load dataset:  47%|████▋     | 1537/3274 [00:02<00:02, 677.87it/s]load dataset:  49%|████▉     | 1616/3274 [00:02<00:02, 704.44it/s]load dataset:  52%|█████▏    | 1690/3274 [00:02<00:02, 704.11it/s]load dataset:  54%|█████▍    | 1769/3274 [00:02<00:02, 725.44it/s]load dataset:  56%|█████▋    | 1844/3274 [00:02<00:02, 706.30it/s]load dataset:  59%|█████▉    | 1929/3274 [00:02<00:01, 745.67it/s]load dataset:  62%|██████▏   | 2037/3274 [00:02<00:01, 837.76it/s]load dataset:  65%|██████▍   | 2123/3274 [00:03<00:01, 783.88it/s]load dataset:  67%|██████▋   | 2203/3274 [00:03<00:01, 764.79it/s]load dataset:  70%|██████▉   | 2282/3274 [00:03<00:01, 770.83it/s]load dataset:  72%|███████▏  | 2370/3274 [00:03<00:01, 801.71it/s]load dataset:  75%|███████▌  | 2456/3274 [00:03<00:01, 817.20it/s]load dataset:  78%|███████▊  | 2539/3274 [00:03<00:00, 814.70it/s]load dataset:  80%|████████  | 2625/3274 [00:03<00:00, 827.11it/s]load dataset:  83%|████████▎ | 2709/3274 [00:03<00:00, 803.02it/s]load dataset:  85%|████████▌ | 2790/3274 [00:03<00:00, 765.46it/s]load dataset:  88%|████████▊ | 2876/3274 [00:03<00:00, 781.14it/s]load dataset:  90%|█████████ | 2955/3274 [00:04<00:00, 747.70it/s]load dataset:  93%|█████████▎| 3031/3274 [00:04<00:00, 689.46it/s]load dataset:  95%|█████████▍| 3101/3274 [00:04<00:00, 653.02it/s]load dataset:  97%|█████████▋| 3168/3274 [00:04<00:00, 583.06it/s]load dataset:  99%|█████████▊| 3228/3274 [00:04<00:00, 513.24it/s]load dataset: 100%|██████████| 3274/3274 [00:04<00:00, 681.95it/s]
12/25/2023 23:02:33 - INFO - __main__ -   ***** Running Test *****
12/25/2023 23:02:33 - INFO - __main__ -     Num examples = 3274
12/25/2023 23:02:33 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/7 [00:00<?, ?it/s]evaluate test:  14%|█▍        | 1/7 [00:04<00:28,  4.70s/it]evaluate test:  29%|██▊       | 2/7 [00:08<00:19,  3.94s/it]evaluate test:  43%|████▎     | 3/7 [00:11<00:14,  3.70s/it]evaluate test:  57%|█████▋    | 4/7 [00:14<00:10,  3.60s/it]evaluate test:  71%|███████▏  | 5/7 [00:18<00:07,  3.53s/it]evaluate test:  86%|████████▌ | 6/7 [00:21<00:03,  3.49s/it]evaluate test: 100%|██████████| 7/7 [00:23<00:00,  2.80s/it]evaluate test: 100%|██████████| 7/7 [00:23<00:00,  3.31s/it]
12/25/2023 23:02:56 - INFO - __main__ -   ***** Test results *****
12/25/2023 23:02:56 - INFO - __main__ -     test_accuracy = 0.9777
12/25/2023 23:02:56 - INFO - __main__ -     test_f1 = 0.7306
12/25/2023 23:02:56 - INFO - __main__ -     test_precision = 0.8919
12/25/2023 23:02:56 - INFO - __main__ -     test_recall = 0.6188
12/25/2023 23:02:56 - INFO - __main__ -     test_threshold = 0.5

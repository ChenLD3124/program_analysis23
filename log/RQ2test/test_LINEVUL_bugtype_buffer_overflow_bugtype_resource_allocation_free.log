12/25/2023 22:34:04 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:34:12 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_resource_allocation_free/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_buffer_overflow', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_resource_allocation_free/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_resource_allocation_free/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_buffer_overflow/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3374 [00:00<?, ?it/s]load dataset:   2%|▏         | 64/3374 [00:00<00:05, 606.83it/s]load dataset:   4%|▍         | 128/3374 [00:00<00:05, 623.84it/s]load dataset:   6%|▌         | 191/3374 [00:00<00:05, 588.51it/s]load dataset:   7%|▋         | 251/3374 [00:00<00:06, 505.50it/s]load dataset:  10%|▉         | 330/3374 [00:00<00:05, 594.79it/s]load dataset:  13%|█▎        | 443/3374 [00:00<00:03, 758.65it/s]load dataset:  16%|█▌        | 543/3374 [00:00<00:03, 814.99it/s]load dataset:  19%|█▊        | 627/3374 [00:00<00:03, 766.55it/s]load dataset:  21%|██        | 709/3374 [00:01<00:03, 777.83it/s]load dataset:  23%|██▎       | 789/3374 [00:01<00:03, 721.89it/s]load dataset:  26%|██▌       | 877/3374 [00:01<00:03, 763.65it/s]load dataset:  28%|██▊       | 955/3374 [00:01<00:03, 737.16it/s]load dataset:  31%|███       | 1042/3374 [00:01<00:03, 772.18it/s]load dataset:  33%|███▎      | 1121/3374 [00:01<00:03, 580.87it/s]load dataset:  37%|███▋      | 1239/3374 [00:01<00:02, 719.32it/s]load dataset:  39%|███▉      | 1321/3374 [00:01<00:02, 714.13it/s]load dataset:  41%|████▏     | 1399/3374 [00:02<00:02, 700.12it/s]load dataset:  44%|████▎     | 1474/3374 [00:02<00:04, 417.24it/s]load dataset:  46%|████▌     | 1559/3374 [00:02<00:03, 493.53it/s]load dataset:  48%|████▊     | 1631/3374 [00:02<00:03, 538.04it/s]load dataset:  50%|█████     | 1699/3374 [00:02<00:03, 527.76it/s]load dataset:  52%|█████▏    | 1762/3374 [00:02<00:03, 510.85it/s]load dataset:  54%|█████▍    | 1828/3374 [00:02<00:02, 544.61it/s]load dataset:  56%|█████▋    | 1906/3374 [00:03<00:02, 494.42it/s]load dataset:  59%|█████▉    | 1995/3374 [00:03<00:02, 583.47it/s]load dataset:  62%|██████▏   | 2098/3374 [00:03<00:01, 690.56it/s]load dataset:  64%|██████▍   | 2174/3374 [00:03<00:01, 707.31it/s]load dataset:  67%|██████▋   | 2250/3374 [00:03<00:01, 700.71it/s]load dataset:  69%|██████▉   | 2324/3374 [00:03<00:01, 658.45it/s]load dataset:  72%|███████▏  | 2426/3374 [00:03<00:01, 749.32it/s]load dataset:  74%|███████▍  | 2507/3374 [00:03<00:01, 764.87it/s]load dataset:  77%|███████▋  | 2592/3374 [00:03<00:00, 785.32it/s]load dataset:  79%|███████▉  | 2673/3374 [00:04<00:00, 787.42it/s]load dataset:  82%|████████▏ | 2753/3374 [00:04<00:00, 787.57it/s]load dataset:  84%|████████▍ | 2833/3374 [00:04<00:00, 740.49it/s]load dataset:  86%|████████▌ | 2909/3374 [00:04<00:00, 723.75it/s]load dataset:  88%|████████▊ | 2985/3374 [00:04<00:00, 728.41it/s]load dataset:  91%|█████████ | 3059/3374 [00:04<00:00, 729.35it/s]load dataset:  93%|█████████▎| 3133/3374 [00:04<00:00, 723.62it/s]load dataset:  95%|█████████▌| 3206/3374 [00:04<00:00, 603.69it/s]load dataset:  97%|█████████▋| 3270/3374 [00:05<00:00, 452.57it/s]load dataset:  98%|█████████▊| 3323/3374 [00:05<00:00, 371.69it/s]load dataset: 100%|█████████▉| 3372/3374 [00:05<00:00, 391.60it/s]load dataset: 100%|██████████| 3374/3374 [00:05<00:00, 616.96it/s]
12/25/2023 22:34:20 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:34:20 - INFO - __main__ -     Num examples = 3374
12/25/2023 22:34:20 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/7 [00:00<?, ?it/s]evaluate test:  14%|█▍        | 1/7 [00:04<00:27,  4.56s/it]evaluate test:  29%|██▊       | 2/7 [00:07<00:19,  3.87s/it]evaluate test:  43%|████▎     | 3/7 [00:11<00:14,  3.65s/it]evaluate test:  57%|█████▋    | 4/7 [00:14<00:10,  3.60s/it]evaluate test:  71%|███████▏  | 5/7 [00:18<00:07,  3.52s/it]evaluate test:  86%|████████▌ | 6/7 [00:21<00:03,  3.49s/it]evaluate test: 100%|██████████| 7/7 [00:23<00:00,  3.01s/it]evaluate test: 100%|██████████| 7/7 [00:23<00:00,  3.38s/it]
12/25/2023 22:34:44 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:34:44 - INFO - __main__ -     test_accuracy = 0.9766
12/25/2023 22:34:44 - INFO - __main__ -     test_f1 = 0.7584
12/25/2023 22:34:44 - INFO - __main__ -     test_precision = 0.8212
12/25/2023 22:34:44 - INFO - __main__ -     test_recall = 0.7045
12/25/2023 22:34:44 - INFO - __main__ -     test_threshold = 0.5

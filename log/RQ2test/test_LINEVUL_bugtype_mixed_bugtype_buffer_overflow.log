12/25/2023 22:41:10 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:41:14 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_mixed', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_buffer_overflow/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_mixed/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/3729 [00:00<?, ?it/s]load dataset:   2%|▏         | 57/3729 [00:00<00:06, 561.80it/s]load dataset:   3%|▎         | 127/3729 [00:00<00:05, 633.30it/s]load dataset:   5%|▌         | 191/3729 [00:00<00:05, 599.01it/s]load dataset:   7%|▋         | 252/3729 [00:00<00:06, 525.87it/s]load dataset:   8%|▊         | 308/3729 [00:00<00:06, 529.39it/s]load dataset:  10%|▉         | 372/3729 [00:00<00:05, 563.73it/s]load dataset:  12%|█▏        | 434/3729 [00:00<00:05, 575.61it/s]load dataset:  13%|█▎        | 501/3729 [00:00<00:05, 594.46it/s]load dataset:  15%|█▌        | 571/3729 [00:00<00:05, 622.80it/s]load dataset:  17%|█▋        | 634/3729 [00:01<00:05, 580.07it/s]load dataset:  19%|█▊        | 693/3729 [00:01<00:05, 519.11it/s]load dataset:  20%|██        | 747/3729 [00:01<00:05, 502.85it/s]load dataset:  21%|██▏       | 799/3729 [00:01<00:06, 462.06it/s]load dataset:  23%|██▎       | 847/3729 [00:01<00:06, 430.67it/s]load dataset:  24%|██▍       | 901/3729 [00:01<00:06, 458.25it/s]load dataset:  26%|██▌       | 967/3729 [00:01<00:05, 511.76it/s]load dataset:  28%|██▊       | 1028/3729 [00:01<00:05, 520.13it/s]load dataset:  29%|██▉       | 1082/3729 [00:02<00:05, 459.18it/s]load dataset:  30%|███       | 1134/3729 [00:02<00:05, 466.15it/s]load dataset:  33%|███▎      | 1214/3729 [00:02<00:04, 553.36it/s]load dataset:  34%|███▍      | 1272/3729 [00:02<00:04, 546.90it/s]load dataset:  36%|███▌      | 1329/3729 [00:02<00:04, 488.19it/s]load dataset:  37%|███▋      | 1380/3729 [00:02<00:05, 463.03it/s]load dataset:  38%|███▊      | 1428/3729 [00:02<00:05, 398.15it/s]load dataset:  39%|███▉      | 1471/3729 [00:02<00:05, 395.41it/s]load dataset:  41%|████      | 1526/3729 [00:03<00:05, 433.82it/s]load dataset:  42%|████▏     | 1572/3729 [00:03<00:06, 333.84it/s]load dataset:  44%|████▍     | 1633/3729 [00:03<00:05, 392.60it/s]load dataset:  47%|████▋     | 1743/3729 [00:03<00:03, 560.73it/s]load dataset:  49%|████▉     | 1827/3729 [00:03<00:03, 630.32it/s]load dataset:  51%|█████     | 1897/3729 [00:03<00:03, 581.30it/s]load dataset:  53%|█████▎    | 1961/3729 [00:03<00:03, 584.59it/s]load dataset:  54%|█████▍    | 2024/3729 [00:03<00:03, 543.68it/s]load dataset:  56%|█████▌    | 2082/3729 [00:04<00:03, 482.32it/s]load dataset:  58%|█████▊    | 2151/3729 [00:04<00:02, 528.71it/s]load dataset:  59%|█████▉    | 2208/3729 [00:04<00:02, 536.16it/s]load dataset:  61%|██████    | 2264/3729 [00:04<00:02, 515.79it/s]load dataset:  62%|██████▏   | 2318/3729 [00:04<00:03, 403.27it/s]load dataset:  64%|██████▍   | 2401/3729 [00:04<00:02, 498.85it/s]load dataset:  66%|██████▌   | 2463/3729 [00:04<00:02, 528.00it/s]load dataset:  68%|██████▊   | 2521/3729 [00:04<00:02, 508.96it/s]load dataset:  70%|██████▉   | 2600/3729 [00:05<00:01, 581.21it/s]load dataset:  72%|███████▏  | 2681/3729 [00:05<00:01, 640.98it/s]load dataset:  74%|███████▍  | 2777/3729 [00:05<00:01, 728.37it/s]load dataset:  77%|███████▋  | 2853/3729 [00:05<00:01, 719.75it/s]load dataset:  79%|███████▉  | 2950/3729 [00:05<00:00, 790.28it/s]load dataset:  81%|████████▏ | 3031/3729 [00:05<00:00, 790.68it/s]load dataset:  83%|████████▎ | 3112/3729 [00:05<00:00, 741.48it/s]load dataset:  85%|████████▌ | 3188/3729 [00:05<00:00, 704.11it/s]load dataset:  87%|████████▋ | 3260/3729 [00:06<00:00, 621.59it/s]load dataset:  89%|████████▉ | 3325/3729 [00:06<00:00, 615.13it/s]load dataset:  91%|█████████ | 3389/3729 [00:06<00:00, 543.60it/s]load dataset:  93%|█████████▎| 3457/3729 [00:06<00:00, 533.08it/s]load dataset:  94%|█████████▍| 3512/3729 [00:06<00:00, 386.08it/s]load dataset:  95%|█████████▌| 3557/3729 [00:06<00:00, 275.81it/s]load dataset:  96%|█████████▋| 3593/3729 [00:07<00:00, 219.93it/s]load dataset:  97%|█████████▋| 3622/3729 [00:07<00:00, 200.96it/s]load dataset:  98%|█████████▊| 3653/3729 [00:07<00:00, 218.24it/s]load dataset:  99%|█████████▊| 3682/3729 [00:07<00:00, 230.90it/s]load dataset:  99%|█████████▉| 3710/3729 [00:07<00:00, 230.39it/s]load dataset: 100%|██████████| 3729/3729 [00:07<00:00, 476.64it/s]
12/25/2023 22:41:35 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:41:35 - INFO - __main__ -     Num examples = 3729
12/25/2023 22:41:35 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/8 [00:00<?, ?it/s]evaluate test:  12%|█▎        | 1/8 [00:04<00:33,  4.81s/it]evaluate test:  25%|██▌       | 2/8 [00:08<00:23,  4.00s/it]evaluate test:  38%|███▊      | 3/8 [00:11<00:18,  3.72s/it]evaluate test:  50%|█████     | 4/8 [00:15<00:14,  3.60s/it]evaluate test:  62%|██████▎   | 5/8 [00:18<00:10,  3.52s/it]evaluate test:  75%|███████▌  | 6/8 [00:21<00:06,  3.46s/it]evaluate test:  88%|████████▊ | 7/8 [00:25<00:03,  3.45s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  2.66s/it]evaluate test: 100%|██████████| 8/8 [00:26<00:00,  3.27s/it]
12/25/2023 22:42:01 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:42:01 - INFO - __main__ -     test_accuracy = 0.9769
12/25/2023 22:42:01 - INFO - __main__ -     test_f1 = 0.8396
12/25/2023 22:42:01 - INFO - __main__ -     test_precision = 0.8789
12/25/2023 22:42:01 - INFO - __main__ -     test_recall = 0.8036
12/25/2023 22:42:01 - INFO - __main__ -     test_threshold = 0.5

12/25/2023 22:47:56 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /data2/chenlida/model/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/25/2023 22:47:59 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/train.jsonl', output_dir='./saved_models/LINEVUL_bugtype_privilege_escalation_authorization', model_type='roberta', block_size=512, eval_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/valid.jsonl', test_data_file='/data2/chenlida/work/fx/data-package/cross_sections/bug_type/bugtype_input_validation/test.jsonl', model_name='model.bin', model_name_or_path='/data2/chenlida/model/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='/data2/chenlida/model/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, eval_export=False, sample=False, no_cuda=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=512, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=1, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
>>>>>>>>>
./saved_models/LINEVUL_bugtype_privilege_escalation_authorization/checkpoint-best-f1/model.bin
>>>>>>>>>>

load dataset:   0%|          | 0/2551 [00:00<?, ?it/s]load dataset:   3%|▎         | 68/2551 [00:00<00:03, 679.83it/s]load dataset:   5%|▌         | 136/2551 [00:00<00:04, 600.91it/s]load dataset:   8%|▊         | 197/2551 [00:00<00:04, 532.34it/s]load dataset:  10%|▉         | 252/2551 [00:00<00:04, 496.45it/s]load dataset:  12%|█▏        | 308/2551 [00:00<00:04, 515.67it/s]load dataset:  15%|█▌        | 386/2551 [00:00<00:03, 586.58it/s]load dataset:  18%|█▊        | 448/2551 [00:00<00:03, 595.69it/s]load dataset:  20%|██        | 513/2551 [00:00<00:03, 580.89it/s]load dataset:  24%|██▍       | 610/2551 [00:01<00:02, 689.73it/s]load dataset:  27%|██▋       | 682/2551 [00:01<00:02, 697.41it/s]load dataset:  30%|██▉       | 754/2551 [00:01<00:02, 695.58it/s]load dataset:  32%|███▏      | 825/2551 [00:01<00:02, 696.02it/s]load dataset:  35%|███▌      | 895/2551 [00:01<00:02, 646.26it/s]load dataset:  38%|███▊      | 961/2551 [00:01<00:02, 618.75it/s]load dataset:  40%|████      | 1024/2551 [00:01<00:02, 585.99it/s]load dataset:  43%|████▎     | 1096/2551 [00:01<00:02, 620.40it/s]load dataset:  45%|████▌     | 1159/2551 [00:01<00:02, 591.63it/s]load dataset:  48%|████▊     | 1219/2551 [00:02<00:02, 546.56it/s]load dataset:  50%|████▉     | 1275/2551 [00:02<00:02, 475.59it/s]load dataset:  52%|█████▏    | 1334/2551 [00:02<00:02, 503.71it/s]load dataset:  56%|█████▌    | 1418/2551 [00:02<00:01, 588.35it/s]load dataset:  58%|█████▊    | 1491/2551 [00:02<00:01, 620.83it/s]load dataset:  62%|██████▏   | 1593/2551 [00:02<00:01, 730.80it/s]load dataset:  66%|██████▋   | 1692/2551 [00:02<00:01, 801.70it/s]load dataset:  70%|██████▉   | 1775/2551 [00:02<00:01, 746.23it/s]load dataset:  73%|███████▎  | 1864/2551 [00:02<00:00, 781.85it/s]load dataset:  76%|███████▋  | 1946/2551 [00:03<00:00, 791.71it/s]load dataset:  79%|███████▉  | 2027/2551 [00:03<00:00, 733.77it/s]load dataset:  83%|████████▎ | 2107/2551 [00:03<00:00, 749.79it/s]load dataset:  86%|████████▌ | 2184/2551 [00:03<00:00, 732.86it/s]load dataset:  89%|████████▊ | 2259/2551 [00:03<00:00, 700.53it/s]load dataset:  92%|█████████▏| 2352/2551 [00:03<00:00, 762.65it/s]load dataset:  95%|█████████▌| 2430/2551 [00:03<00:00, 542.94it/s]load dataset:  98%|█████████▊| 2494/2551 [00:04<00:00, 390.61it/s]load dataset: 100%|█████████▉| 2545/2551 [00:04<00:00, 354.54it/s]load dataset: 100%|██████████| 2551/2551 [00:04<00:00, 583.93it/s]
12/25/2023 22:48:07 - INFO - __main__ -   ***** Running Test *****
12/25/2023 22:48:07 - INFO - __main__ -     Num examples = 2551
12/25/2023 22:48:07 - INFO - __main__ -     Batch size = 512
evaluate test:   0%|          | 0/5 [00:00<?, ?it/s]evaluate test:  20%|██        | 1/5 [00:04<00:18,  4.72s/it]evaluate test:  40%|████      | 2/5 [00:08<00:11,  3.94s/it]evaluate test:  60%|██████    | 3/5 [00:11<00:07,  3.68s/it]evaluate test:  80%|████████  | 4/5 [00:14<00:03,  3.56s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.49s/it]evaluate test: 100%|██████████| 5/5 [00:18<00:00,  3.65s/it]
12/25/2023 22:48:25 - INFO - __main__ -   ***** Test results *****
12/25/2023 22:48:25 - INFO - __main__ -     test_accuracy = 0.9741
12/25/2023 22:48:25 - INFO - __main__ -     test_f1 = 0.7179
12/25/2023 22:48:25 - INFO - __main__ -     test_precision = 0.866
12/25/2023 22:48:25 - INFO - __main__ -     test_recall = 0.6131
12/25/2023 22:48:25 - INFO - __main__ -     test_threshold = 0.5
